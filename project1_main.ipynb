{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dependencies.\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import requests\n",
    "import time\n",
    "from api_key import ip_api_key\n",
    "from api_key import ip_api_key2\n",
    "from api_key import ip_api_key3\n",
    "from api_key import ip_api_key4\n",
    "from api_key import ip_api_key5\n",
    "from datetime import datetime\n",
    "from scipy.stats import f_oneway\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import hvplot.pandas\n",
    "from holoviews.util.transform import lon_lat_to_easting_northing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to csv.\n",
    "card_fraud_path_load = Path(\"resource/merged_file.csv\")\n",
    "card_data = pd.read_csv(card_fraud_path_load)\n",
    "\n",
    "card_fraud_ernie_path_load = Path(\"resource/credit_card_fraud_flg_ernie.csv\")\n",
    "card_data_ernie = pd.read_csv(card_fraud_ernie_path_load)\n",
    "\n",
    "card_fraud_thet_path_load = Path(\"resource/credit_card_fraud_flg_thet.csv\")\n",
    "card_data_thet = pd.read_csv(card_fraud_thet_path_load)\n",
    "\n",
    "card_fraud_jimmy_path_load = Path(\"resource/credit_card_fraud_flg_jimmy.csv\")\n",
    "card_data_jimmy = pd.read_csv(card_fraud_jimmy_path_load)\n",
    "\n",
    "card_fraud_mounika_path_load = Path(\"resource/credit_card_fraud_flg_mounika.csv\")\n",
    "card_data_mounika = pd.read_csv(card_fraud_mounika_path_load)\n",
    "\n",
    "card_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ip_data(df, api_key):\n",
    "    # Base URL for the API\n",
    "    base_url = f'https://api.ipgeolocation.io/ipgeo?'\n",
    "    query_url_template = f\"{base_url}apiKey={api_key}&ip=\"\n",
    "    # Define an empty list to fetch the ipgeio data for each ip address\n",
    "    ip_data = []\n",
    "    # Print to logger\n",
    "    print(\"Beginning Data Retrieval     \")\n",
    "    print(\"-----------------------------\")\n",
    "    # Create counters\n",
    "    record_count = 1\n",
    "    set_count = 1\n",
    "    # Loop through all the ip addresses to fetch ip geo location data\n",
    "    for i, row in df.iterrows():\n",
    "        ip_address = row['IP Address']\n",
    "        transaction_id = row['Transaction ID']\n",
    "        # Group cities in sets of 50 for logging purposes\n",
    "        if (i % 50 == 0 and i >= 50):\n",
    "            set_count += 1\n",
    "            record_count = 0\n",
    "        # Log the url, record, and set numbers\n",
    "        print(f\"Processing Record {record_count} of Set {set_count}|{ip_address}\")\n",
    "        # Add 1 to the record count\n",
    "        record_count += 1\n",
    "        # Run an API request for each of the ip addresses\n",
    "        try:\n",
    "            query_url = f\"{query_url_template}{ip_address}\"\n",
    "            # Parse the JSON and retrieve data\n",
    "            ip_geo = requests.get(query_url).json()\n",
    "            # Parse out city, latitude, longitude, continent name, country capital and country name\n",
    "            ip_city = ip_geo.get('city','N/A')\n",
    "            ip_latitude = ip_geo.get('latitude','N/A')\n",
    "            ip_longitude = ip_geo.get('longitude','N/A')\n",
    "            ip_continent_name = ip_geo.get('continent_name','N/A')\n",
    "            ip_country_capital = ip_geo.get('country_capital','N/A')\n",
    "            ip_country_name = ip_geo.get('country_name','N/A')\n",
    "            # Append the City information into city_data list\n",
    "            ip_data.append({\n",
    "                \"Transaction ID\": transaction_id,\n",
    "                \"IP\": ip_address,\n",
    "                \"City\": ip_city,\n",
    "                \"Lat\": ip_latitude,\n",
    "                \"Lng\": ip_longitude,\n",
    "                \"Continent\": ip_continent_name,\n",
    "                \"Capital\": ip_country_capital,\n",
    "                \"Country\": ip_country_name\n",
    "            })\n",
    "        # If an error is experienced, skip the ip address\n",
    "        except requests.RequestException as e:\n",
    "            print(\"IP Address not found. Skipping...\")\n",
    "            continue\n",
    "    #Convert the list of dictionaries to a DataFrame\n",
    "    ip_data_df = pd.DataFrame(ip_data)\n",
    "    # Indicate that Data Loading is complete\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"Data Retrieval Complete      \")\n",
    "    print(\"-----------------------------\")\n",
    "    return ip_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data_thet = fetch_ip_data(card_data_thet, ip_api_key2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data_ernie = fetch_ip_data(card_data_ernie, ip_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data_jimmy = fetch_ip_data(card_data_jimmy, ip_api_key3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_data_mounika = fetch_ip_data(card_data_mounika, ip_api_key4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path(\"resource/thet_ip_asn_geolocation_data.csv\")\n",
    "ip_data_thet.to_csv(output_path, index = False)\n",
    "\n",
    "output_path = Path(\"resource/ernie_ip_asn_geolocation_data.csv\")\n",
    "ip_data_ernie.to_csv(output_path, index = False)\n",
    "\n",
    "output_path = Path(\"resource/jimmy_ip_asn_geolocation_data.csv\")\n",
    "ip_data_jimmy.to_csv(output_path, index = False)\n",
    "\n",
    "output_path = Path(\"resource/mounika_ip_asn_geolocation_data.csv\")\n",
    "ip_data_mounika.to_csv(output_path, index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined the four csv files for IP Geolocation Data \n",
    "# Define file paths\n",
    "file_paths = [\n",
    "    Path(\"resource/ernie_ip_geolocation_data.csv\"),\n",
    "    Path(\"resource/jimmy_ip_geolocation_data.csv\"),\n",
    "    Path(\"resource/thet_ip_geolocation_data.csv\"),\n",
    "    Path(\"resource/mounika_ip_geolocation_data.csv\")\n",
    "]\n",
    "\n",
    "# Load each CSV file into a separate DataFrame\n",
    "dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Optionally, save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(\"resource/combined_file.csv\", index=False)\n",
    "\n",
    "# Display the first few rows of the combined DataFrame\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the combined_df into the merged_file\n",
    "# Load the credit card fraud data\n",
    "credit_card_fraud_file_path = Path(\"resource/credit_card_fraud.csv\")\n",
    "credit_card_fraud_df = pd.read_csv(credit_card_fraud_file_path)\n",
    "\n",
    "# Merge combined_df with credit_card_fraud_df on 'Transaction ID'\n",
    "merged_df = pd.merge(combined_df, credit_card_fraud_df, on='Transaction ID', how='inner')\n",
    "\n",
    "output_path = Path(\"resource/merged_file.csv\")\n",
    "merged_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data=card_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General info on data.\n",
    "card_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counted how many (potential) fraud or valid transactions there are in the data.\n",
    "fraud_data = card_data[card_data['Fraud Flag or Label'] == 1]\n",
    "fraud_data_count = len(fraud_data)\n",
    "valid_data_row = card_data[card_data['Fraud Flag or Label'] == 0]\n",
    "valid_data_count = len(valid_data_row)\n",
    "print(f\"There are {fraud_data_count} fraud or flag or labeled transactions in the dataset.\")\n",
    "print(f\"There are {valid_data_count} valid transactions in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_data['Cardholder Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardholder names that has fraud or flag or labeled transactions. (more than 1 means multiple transactions.)\n",
    "fraudulent_cardholder = fraud_data.groupby(['Cardholder Name']).size()\n",
    "fraudulent_cardholder.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if there is any null value in the column.\n",
    "card_data['Transaction Date and Time'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatted the column into a date form.\n",
    "card_data_transaction_date = pd.to_datetime(card_data['Transaction Date and Time'], format ='%Y-%m-%d %H:%M:%S')\n",
    "card_data_expiration_date = pd.to_datetime(card_data['Card Expiration Date'], format='%m/%y')\n",
    "card_data[\"Merchant Category Code (MCC)\"]=card_data[\"Merchant Category Code (MCC)\"].astype(int)\n",
    "card_data_transaction_date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the fraudulent transactions data\n",
    "flagged_data = card_data[card_data['Fraud Flag or Label'] == 1].copy()\n",
    "\n",
    "# Convert the 'Transaction Date and Time' column to datetime\n",
    "flagged_data['Transaction Date and Time'] = pd.to_datetime(fraud_data['Transaction Date and Time'], format ='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Extract the month and hour from the transaction date\n",
    "flagged_data['Month'] = flagged_data['Transaction Date and Time'].dt.month\n",
    "flagged_data['Hour'] = flagged_data['Transaction Date and Time'].dt.hour\n",
    "\n",
    "# Group by month & hour and count the number of transactions\n",
    "flagged_transactions_per_month = flagged_data.groupby('Month').size()\n",
    "flagged_transactions_per_hour = flagged_data.groupby('Hour').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample group by with Month and transaction ID\n",
    "flagged_transactions_per_month_id = flagged_data.groupby(['Month', 'Transaction ID']).size()\n",
    "flagged_transactions_per_month_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperated all the date data into 'year', 'month', 'day'.\n",
    "card_data_transaction_year = card_data_transaction_date.dt.year\n",
    "card_data_transaction_month = card_data_transaction_date.dt.month\n",
    "card_data_transaction_day = card_data_transaction_date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for transaction date distribution.\n",
    "plt.hist(card_data_transaction_date, bins=50, edgecolor='white')\n",
    "plt.title(\"Transactions date distribution\")\n",
    "plt.xlabel(\"transaction_date\")\n",
    "plt.xticks(rotation=90, ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created new columns regarding year.\n",
    "transactions_per_year = card_data.groupby(card_data_transaction_year).size()\n",
    "transactions_per_year = transactions_per_year.reset_index()\n",
    "transactions_per_year.columns = ['Year', 'Transaction per year']\n",
    "transactions_per_year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created bar graph to show transactions per year.\n",
    "x_axis = transactions_per_year['Year']\n",
    "y_axis = transactions_per_year['Transaction per year']\n",
    "\n",
    "tick_locations = []\n",
    "\n",
    "for x in x_axis:\n",
    "    tick_locations.append(x)\n",
    "\n",
    "plt.bar(x_axis, y_axis, color=\"darkblue\", alpha=0.9, align=\"center\", width=0.55)\n",
    "plt.xticks(tick_locations, rotation=90, ha='center')\n",
    "plt.title(\"# of transactions per year \")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"# of Transactions\")\n",
    "plt.savefig('output/Fig1.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can easily see that the transactions through credit card has significantly decreased on the year '2023', we believe that the after math of covid-19 has carried over until the 2020 to 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created new columns regarding month.\n",
    "transactions_per_month = card_data.groupby(card_data_transaction_month).size()\n",
    "transactions_per_month = transactions_per_month.reset_index()\n",
    "transactions_per_month.columns = ['Month', 'Transactions per month']\n",
    "transactions_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created bar graph to show transactions per month. (1 = January)\n",
    "x_axis = transactions_per_month['Month']\n",
    "y_axis = transactions_per_month['Transactions per month']\n",
    "\n",
    "plt.plot(x_axis, y_axis, color=\"darkblue\", alpha=0.9)\n",
    "plt.title(\"# of transactions per month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"# of Transactions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the yearly transaction graph, we dig little deeper and look at the trends on monthly transactions. Surprisingly, the amount of transactions from users significantly dips on the September and going into the end of the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of fraudulent transactions per month\n",
    "x_axis = flagged_transactions_per_month.index\n",
    "y_axis = flagged_transactions_per_month.values\n",
    "\n",
    "plt.plot(x_axis, y_axis, color=\"darkblue\", alpha=0.9)\n",
    "plt.title(\"# of Flagged Transactions per Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"# of Flagged Transactions\")\n",
    "plt.savefig('output/Fig2.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created bar graph\n",
    "x_axis = flagged_transactions_per_hour.index\n",
    "y_axis = flagged_transactions_per_hour.values\n",
    "\n",
    "plt.bar(x_axis, y_axis, alpha=0.9)\n",
    "plt.title(\"# of Flagged Transactions per Hour\")\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"# of Flagged Transactions\")\n",
    "plt.savefig('output/Fig3.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on this bar graph we can see that 5:00am, 10:00am, 7:00pm has the highest flagged transactions; therefore, as a credit card company they need to staff the customer support agents to appropriate time slot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to get the total count of fraudulent transactions per month\n",
    "fraud_transactions_per_month_id_0 = flagged_transactions_per_month_id.groupby(level=0).count()\n",
    "\n",
    "x_axis = fraud_transactions_per_month_id_0.index\n",
    "y_axis = fraud_transactions_per_month_id_0.values\n",
    "\n",
    "# Perform linear regression\n",
    "(slope, intercept, r_value, p_value, std_err) = linregress(x_axis, y_axis)\n",
    "\n",
    "# Create equation of line to calculate predicted fraudulent transaction\n",
    "line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "\n",
    "# Generate a scatter plot of fraudulent transactions over months\n",
    "plt.scatter(x_axis, y_axis, alpha=0.9)\n",
    "plt.title(\"# of Flagged Transactions per Month\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"# of Flagged Transactions\")\n",
    "\n",
    "# Plot the regression line\n",
    "plt.plot(x_axis, intercept + slope*x_axis, 'r', label='fitted line')\n",
    "\n",
    "# Annotate the plot with the linear equation\n",
    "plt.annotate(line_eq, xy=(0.15, 0.35), xycoords='axes fraction', fontsize=15, color=\"red\")\n",
    "\n",
    "print(f\"The r_value is: {r_value}\")\n",
    "plt.savefig('output/Fig4.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The r-value of -0.74 suggest that there is a strong negative correlation between the month (x-axis) and the number of flagged transactions (y-axis). This means that as time progresses, the number of flagged transactions tends to decrease. For each month that passes, the model predicts approximately 7.93 fewer flagged transactions. However, this is a simple model and doesn’t prove causation, so other factors could also be influencing the decrease in flagged transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange rates to USD (example rates, replace with actual rates)\n",
    "exchange_rates = {\n",
    "    \"USD\": 1.0,    # USD to USD\n",
    "    \"EUR\": 1.2,    # 1 EUR = 1.2 USD\n",
    "    \"INR\": 0.013   # 1 INR = 0.013 USD\n",
    "}\n",
    "\n",
    "# Function to convert amounts to USD\n",
    "def convert_to_usd(amount, currency):\n",
    "    return amount * round(exchange_rates[currency],2)\n",
    "\n",
    "# Apply conversion to the dataframe\n",
    "flagged_data[\"Amount in USD\"] = flagged_data.apply(lambda row: convert_to_usd(row[\"Transaction Amount\"], row[\"Transaction Currency\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average transaction amount for each category and sort as per the provided parameters\n",
    "card_type_avg = flagged_data.groupby(\"Card Type\")[\"Amount in USD\"].mean().sort_values(ascending=False).reset_index()\n",
    "device_type_avg = flagged_data.groupby(\"Device Information\")[\"Amount in USD\"].mean().sort_values(ascending=False).reset_index()\n",
    "currency_type_avg = flagged_data.groupby(\"Transaction Currency\")[\"Amount in USD\"].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Bar width\n",
    "bar_width = 0.5\n",
    "\n",
    "# Set bar positions for each category with a small gap between categories\n",
    "gap = 1\n",
    "r1 = np.arange(len(card_type_avg))\n",
    "r2 = np.arange(len(device_type_avg)) + len(card_type_avg) + gap\n",
    "r3 = np.arange(len(currency_type_avg)) + len(card_type_avg) + len(device_type_avg) + 2 * gap\n",
    "\n",
    "# Plot bars\n",
    "bars1 = plt.bar(r1, card_type_avg[\"Amount in USD\"], color=\"skyblue\", width=bar_width, edgecolor=\"grey\", label=\"Card Type\", alpha=0.5)\n",
    "bars2 = plt.bar(r2, device_type_avg[\"Amount in USD\"], color=\"yellow\", width=bar_width, edgecolor=\"grey\", label=\"Device Information\", alpha=0.5)\n",
    "bars3 = plt.bar(r3, currency_type_avg[\"Amount in USD\"], color=\"green\", width=bar_width, edgecolor=\"grey\", label=\"Transaction Currency\", alpha=0.5)\n",
    "\n",
    "# Add labels for x-axis\n",
    "all_positions = list(r1) + list(r2) + list(r3)\n",
    "all_labels = list(card_type_avg[\"Card Type\"]) + list(device_type_avg[\"Device Information\"]) + list(currency_type_avg[\"Transaction Currency\"])\n",
    "\n",
    "plt.xlabel(\"Category\", fontsize=14)\n",
    "plt.xticks(all_positions, all_labels, rotation=45, ha='right', fontsize=12)\n",
    "\n",
    "# Adding titles and labels\n",
    "plt.title(\"Average Amount in USD by Category\", fontsize=16)\n",
    "plt.ylabel(\"Average Amount in USD\", fontsize=14)\n",
    "\n",
    "# Adding a legend\n",
    "plt.legend()\n",
    "\n",
    "# Adding text labels inside the bars\n",
    "for bar in bars1:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "for bar in bars2:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "for bar in bars3:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, yval, round(yval, 2), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig('output/Fig5.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating subplots for 3 categories vs transxn amount\n",
    "# Create a figure with subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "# Box Plot for Card Type\n",
    "axes[0].boxplot([group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Card Type')])\n",
    "axes[0].set_title('Box Plot of Amount in USD by Card Type',fontsize=14)\n",
    "axes[0].set_xticklabels(flagged_data['Card Type'].unique(), rotation=45, ha='right',fontsize=14)\n",
    "\n",
    "# Box Plot for Device Information\n",
    "axes[1].boxplot([group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Device Information')])\n",
    "axes[1].set_title('Box Plot of Amount in USD by Device Information',fontsize=14)\n",
    "axes[1].set_xticklabels(flagged_data['Device Information'].unique(), rotation=45, ha='right',fontsize=14)\n",
    "\n",
    "# Box Plot for Transaction Currency\n",
    "axes[2].boxplot([group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Transaction Currency')])\n",
    "axes[2].set_title('Box Plot of Amount in USD by Transaction Currency',fontsize=14)\n",
    "axes[2].set_xticklabels(flagged_data['Transaction Currency'].unique(), rotation=45, ha='right',fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform ANOVA using statsmodels\n",
    "# Combine all categorical columns into a long format for ANOVA\n",
    "df_long = pd.melt(flagged_data, id_vars=['Amount in USD'], value_vars=['Card Type', 'Device Information', 'Transaction Currency'],\n",
    "                  var_name='Category', value_name='Type')\n",
    "\n",
    "# Perform ANOVA using statsmodels\n",
    "model = ols('Q(\"Amount in USD\") ~ C(Type)', data=df_long).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "print(anova_table)\n",
    "\n",
    "# Perform ANOVA using scipy.stats (for each category separately)\n",
    "card_type_anova = f_oneway(*[group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Card Type')])\n",
    "device_type_anova = f_oneway(*[group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Device Information')])\n",
    "currency_type_anova = f_oneway(*[group[\"Amount in USD\"].values for name, group in flagged_data.groupby('Transaction Currency')])\n",
    "\n",
    "print(\"ANOVA results for Card Type:\", card_type_anova)\n",
    "print(\"ANOVA results for Device Information:\", device_type_anova)\n",
    "print(\"ANOVA results for Transaction Currency:\", currency_type_anova)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA Results Interpretation:\n",
    "Card Type:\n",
    "\n",
    "\n",
    "p-value: 0.025\n",
    "Interpretation:\n",
    "\n",
    "The p-value (0.025) is less than the typical significance level of 0.05, indicating that there are statistically significant differences in the average transaction amounts across different Card Types.\n",
    "\n",
    "Device Information:\n",
    "p-value: 0.316\n",
    "Interpretation:\n",
    "\n",
    "The p-value (0.316) is greater than 0.05, indicating that there is no statistically significant difference in the average transaction amounts across different Device Information categories.\n",
    "\n",
    "\n",
    "Transaction Currency:\n",
    "p-value: 0.0\n",
    "Interpretation:\n",
    "\n",
    "The p-value (0.0) is much less than 0.05, indicating a highly significant difference in the average transaction amounts across different Transaction Currencies.\n",
    "\n",
    "Conclusion:\n",
    "Card Type: There are significant differences in average transaction         amounts between different card types.\n",
    "\n",
    "Device Information: There are no significant differences in average transaction amounts between different device types.\n",
    "\n",
    "Transaction Currency: There are highly significant differences in average transaction amounts between different currencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_counts = flagged_data[\"Transaction Source\"].value_counts()\n",
    "source_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The data shows a nearly even split between In-Person and Online transactions.\n",
    "In-Person transactions are slightly higher by a margin of 59 transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing Merchant Category Codes and thier occurences\n",
    "mcc_counts =flagged_data[\"Merchant Category Code (MCC)\"].value_counts()\n",
    "mcc_counts=mcc_counts.reset_index()\n",
    "mcc_counts.columns=[\"Mcc\",\"Counts\"]\n",
    "filtered_mcc=mcc_counts.loc[mcc_counts[\"Counts\"]==4]\n",
    "\n",
    "#Providing description to the MCC\n",
    "bins = [0, 1500, 3000, 3300, 3500, 4000, 4800, 5000, 5700, 7300, 8000, 9000, 10000]\n",
    "descriptions = [\n",
    "    \"Agricultural services\",\n",
    "    \"Contracted services\",\n",
    "    \"Airlines\",\n",
    "    \"Car rentals\",\n",
    "    \"Lodging\",\n",
    "    \"Transportation services\",\n",
    "    \"Utility services\",\n",
    "    \"Retail outlet services\",\n",
    "    \"Miscellaneous stores\",\n",
    "    \"Business services\",\n",
    "    \"Professional services and membership organizations\",\n",
    "    \"Government services\"\n",
    "]\n",
    "#Adding Description column to MCC\n",
    "final_mcc = filtered_mcc.copy()\n",
    "final_mcc.loc[:, \"Description\"] = pd.cut(filtered_mcc[\"Mcc\"], bins, labels=descriptions, include_lowest=True)\n",
    "final_mcc\n",
    "\n",
    "#Filtering MCC codes with max occurence of 4\n",
    "grouped_df = final_mcc.groupby('Description',observed=True)[\"Counts\"].sum().reset_index()\n",
    "filtered_df = grouped_df[grouped_df['Counts'] >= 4]\n",
    "\n",
    "#Sorting MCC by their number of occurences\n",
    "filtered_df = filtered_df.reset_index(drop=True).sort_values(by='Counts', ascending=False)\n",
    "print(filtered_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This portion of the analysis contains observing Capital and the average transaction amounts where fraudulent flag equals 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique number of capital in the database\n",
    "flagged_data['Capital'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows based on Country\n",
    "card_data_dedup = flagged_data.drop_duplicates(subset=['Capital'])\n",
    "\n",
    "# Check that the filtered data frame is the same size as the number of unique countries\n",
    "card_data_dedup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the Dataframe by Country\n",
    "card_data_dedup = card_data_dedup.sort_values('Capital')\n",
    "\n",
    "# Set country as index\n",
    "#card_data_dedup.set_index('Country', inplace=True)\n",
    "\n",
    "# Display Sample Data\n",
    "card_data_dedup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what are the top countries number of fruads occured \n",
    "flagged_data['Capital'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean value of Transaction Amount Per Country\n",
    "avg_txn_amt_by_cntry = flagged_data.groupby('Capital', as_index=False)['Transaction Amount'].mean()\n",
    "avg_txn_amt_by_cntry = avg_txn_amt_by_cntry.sort_values('Capital')\n",
    "avg_txn_amt_by_cntry['Transaction Amount'] = round(avg_txn_amt_by_cntry['Transaction Amount'],2)\n",
    "\n",
    "# Display sample data and check that it has the same number of rows as the dedup table\n",
    "avg_txn_amt_by_cntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the dedup dataframe and the fraud transaction mean dataframe\n",
    "card_data_dedup_txn = pd.merge(card_data_dedup, avg_txn_amt_by_cntry, how=\"left\", on=['Capital'])\n",
    "\n",
    "# Rename the new merged column to Avg. Transaction Amount\n",
    "card_data_dedup_txn.rename(columns={'Transaction Amount_y': 'Avg. Transaction Amount'}, inplace=True)\n",
    "\n",
    "# Reset the index\n",
    "card_data_dedup_txn.reset_index()\n",
    "\n",
    "# Display sample data\n",
    "card_data_dedup_txn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter columns for Map - Capital, Lat, Lng, Avg transact Amount, Continent, \n",
    "map_df = card_data_dedup_txn[['Capital', 'Lat', 'Lng', 'Avg. Transaction Amount', 'Continent']]\n",
    "\n",
    "# Display sample data\n",
    "map_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the coordinates to Web Mercator\n",
    "map_df['x'], map_df['y'] = lon_lat_to_easting_northing(map_df.Lng, map_df.Lat)\n",
    "\n",
    "# Display sample data\n",
    "map_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The following image is derived by calling \n",
    " ip Geo location API (web source:  https://app.ipgeolocation.io/) using the IP Address provided in the data source.\n",
    " The API uses the IP address passed as an argument and returns information such as the Latitude, Longtitude, Country Name, \n",
    " Country's Capital and Continent which we will use for analysis.\n",
    "\n",
    "\n",
    "Based on the geo location map below, we observe that most of the credit card transactions where Fraud Flag = 1 take place in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Minimum and Maximum Avg. Transaction Amounts\n",
    "print(\"Max Ave. Transaction Amount: \" + str(max(map_df['Avg. Transaction Amount'])))\n",
    "print(\"Min Ave. Transaction Amount: \" + str(min(map_df['Avg. Transaction Amount'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ranges for marker size to plot\n",
    "bins = [0, 1000, 2000, 3000, 4000, 5000]\n",
    "\n",
    "# The labels list will be used for plotting - Marker size\n",
    "labels = ['50', '100', '150', '200', '250']\n",
    "map_df['Marker'] = pd.cut(map_df['Avg. Transaction Amount'], bins=bins, labels=labels)\n",
    "\n",
    "# Convert the Dataframe into numeric for Marker size\n",
    "map_df['Marker'] = pd.to_numeric(map_df['Marker'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot map - Fraudulent Transactions by Capital\n",
    "map_plot_1 = map_df.hvplot.points(\n",
    "    'x', \n",
    "    'y', \n",
    "    tiles = True,\n",
    "    frame_width = 800,\n",
    "    frame_height = 600, \n",
    "    alpha=0.7,\n",
    "    size = \"Marker\",\n",
    "    color = 'Capital',\n",
    "    hover_cols = ['Capital', 'Avg. Transaction Amount', 'Continent'],\n",
    "    title='Flagged Transactions by Capital'\n",
    "    )\n",
    "\n",
    "map_plot_1\n",
    "#hvplot.save(map_plot_1, 'output/Fig6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The average fraudulent transaction amount was calculated and charted against latitue to see if there are any correlations between the two. There does not appear to be any significat correlation between these 2 measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the scatter plots for latitude vs. average fradulent transaction amount\n",
    "x_values = card_data_dedup_txn['Lat']\n",
    "y_values = card_data_dedup_txn['Avg. Transaction Amount']\n",
    "\n",
    "# Plot the scatter plot with datapoints edge folor = black and opicity=90%\n",
    "plt.scatter(x_values,y_values,alpha=0.9, edgecolors='black')\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel('Average Flagged Transaction Amount')\n",
    "plt.grid('on')\n",
    "\n",
    "# Show plot\n",
    "plt.savefig('output/Fig7.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the count for each continent\n",
    "map_df['Continent'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "\n",
    "The Pie chart below helps us visualize the distribution of flagged activities between continents. As previously note, Europe had the most activities followed by Asia and Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a pie plot showing the distribution of Continents with fraudulent activities\n",
    "\n",
    "# Get the labels and values \n",
    "seriesLabels_pie = ['Europe','Asia','Africa','North America','South America','Oceania']\n",
    "seriesValues_pie = map_df['Continent'].value_counts()\n",
    "\n",
    "# Draw bar chart\n",
    "plt.pie(seriesValues_pie, labels=seriesLabels_pie, autopct='%1.0f%%',startangle=180)\n",
    "\n",
    "# Set the labels\n",
    "plt.title(\"Distribution of Continents with Flagged Activities\")\n",
    "\n",
    "# Show the pie chart\n",
    "plt.savefig('output/Fig8.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
